{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkHEHL9WLDeu"
      },
      "source": [
        "\n",
        "# <font color=\"red\"> Cuaderno 2. Compilación y entrenamiento de modelos en  Tensorflow  y Keras. </font>\n",
        "\n",
        "## <font color=\"blue\"> Por Alfredo Alfredo Diaz </font>\n",
        "\n",
        "![image](https://github.com/adiacla/bigdata/blob/master/Keras-vs-TensorFlow-vs-PyTorch.jpg?raw=true)\n",
        "\n",
        "**Keras**\n",
        "\n",
        "Keras es una librería escrita en Python, diseñada específicamente para hacer experimentos con redes neuronales. Permite crear prototipos rápidamente y de manera fácil, pues está pensada para que sea fácil de usar.\n",
        "\n",
        "Tener la posibilidad de pasar de una idea a un resultado con el mínimo retraso posible es clave cuando haces investigación.\n",
        "\n",
        "**Pytorch**\n",
        "\n",
        "Pytorch es un framework de Python que permite el crecimiento rápido del Deep Learning, con una fuerte aceleración de la GPU. La característica principal de Pytorch es que utiliza grafos computacionales dinámicos. Todos los frameworks de Deep Learning utilizan un lenguaje, como Python en este caso, y un grafo computacional. Esto funciona así por cuestiones de eficiencia y optimización, pues un grafo computacional corre en paralelo en la GPU.\n",
        "\n",
        "\n",
        "**TensorFlow**\n",
        "\n",
        "Cuando una red neuronal se vuelve más compleja, llena de capas y parámetros, el proceso se vuelve mucho más complejo. Es aquí donde entra TensorFlow, una librería de computación numérica que computa gradientes automáticamente, esto quiere decir que está a un nivel más bajo y profundo que Keras o Pytorch.\n",
        "\n",
        "TensorFlow fue desarrollada por Google y la utilizan empresas como Airbnb, Dropbox, Uber y Snapchat. Aunque es muy popular es más recomendable para proyectos grandes y quizás más complejos, pues te da mucho control cuando estás construyendo redes neuronales.\n",
        "\n",
        "Si quieres aprender a diseñar redes neuronales y crear prototipos de manera rápida para entender cómo funcionan, una librería como Keras es ideal, pues incluso ésta utiliza TensorFlow por debajo para computar gradientes, pero sin que tengas que involucrarte con eso. Pytorch combina las dos cosas, pues te ayuda a construir las redes y computa los gradientes automáticamente.\n",
        "\n",
        "**Scikit-learn**\n",
        "\n",
        "Otra librería ideal para diseñar y entrenar redes neuronales es Scikit-learn, que también está escrita en Python y que utilizan empresas como Spotify, Booking y Evernote. Emplea algoritmos de clasificación (determina a qué categoría pertenece un objeto), regresión (asocia atributos de valor continuo a objetos) y agrupamiento (agrupa objetos similares en conjuntos); y opera de manera simultánea con librerías como NumPy y SciPy.\n",
        "\n",
        "**Librerías de Python relacionadas con Redes Neuronales**\n",
        "\n",
        "![imagen](https://aitalks.es/wp-content/uploads/2020/06/Portada-librerias-python.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFgyWZnOA1Pv"
      },
      "source": [
        "#Tensorflow\n",
        "\n",
        "**Instalación y Configuración**\n",
        "Antes de comenzar, asegúrate de tener Python instalado en tu máquina. Para instalar TensorFlow, ejecuta el siguiente comando:\n",
        "\n",
        "      pip install tensorflow\n",
        "\n",
        "\n",
        "Si está usando google colab ya tienes instalado tensorflow y keras, si estas usando tu ambiente propio, recomendamos instalar TensorFlow en un entorno virtual para evitar conflictos con otras librerías. Para crear y activar un entorno virtual, usa:\n",
        "\n",
        "    # Crear entorno virtual\n",
        "    python -m venv tf_env\n",
        "\n",
        "    # Activar el entorno (Windows)\n",
        "    tf_env\\Scripts\\activate\n",
        "\n",
        "    # Activar el entorno (Mac/Linux)\n",
        "    source tf_env/bin/activate\n",
        "\n",
        "TensorFlow opera principalmente con arreglos multidimensionales llamados tensores, que son la base de cualquier modelo de aprendizaje automático. Estos tensores son similares a matrices y arrays de bibliotecas como NumPy, pero ofrecen capacidades adicionales, como la ejecución en hardware especializado como GPU.\n",
        "\n",
        "Un tensor tiene dos atributos principales que debemos comprender:\n",
        "\n",
        "* shape: Describe la dimensión del tensor a lo largo de cada uno de sus ejes.\n",
        "* dtype: Especifica el tipo de datos que contiene, como float32, int32, etc.\n",
        "\n",
        "Vamos a ir trabajando con tensorflow para crear y trabajar con tensores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFyhwzynhk6I",
        "outputId": "2c80b704-c464-4327-fd1e-096f87c88965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.12.12\n"
          ]
        }
      ],
      "source": [
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwdy3k1vDAQX",
        "outputId": "4a3c8182-e747-4c8e-883b-20030d46159e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.19.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "#Es importante usar la misma versión del tensorflow cuando se entrena y se despliegua."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjukwbxXQhJA",
        "outputId": "39ea66df-e838-48c8-e3f4-4d904081e333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensorflow                               2.19.0\n",
            "tensorflow-datasets                      4.9.9\n",
            "tensorflow_decision_forests              1.12.0\n",
            "tensorflow-hub                           0.16.1\n",
            "tensorflow-metadata                      1.17.3\n",
            "tensorflow-probability                   0.25.0\n",
            "tensorflow-text                          2.19.0\n"
          ]
        }
      ],
      "source": [
        "#listar las librerias instaladas que son tensorflow\n",
        "!pip list | grep tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRFEeeScQnl-",
        "outputId": "6105ae65-a365-4a81-cc84-004fbcee006f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keras                                    3.10.0\n",
            "keras-hub                                0.21.1\n",
            "keras-nlp                                0.21.1\n",
            "tf_keras                                 2.19.0\n"
          ]
        }
      ],
      "source": [
        "#listar librerias keras\n",
        "!pip list | grep keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBEq6xu6QuKp",
        "outputId": "04ae3caf-3327-4a47-cb3e-a6128aff059f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch                                    2.9.0+cu128\n",
            "torchao                                  0.10.0\n",
            "torchaudio                               2.9.0+cu128\n",
            "torchcodec                               0.8.0+cu128\n",
            "torchdata                                0.11.0\n",
            "torchsummary                             1.5.1\n",
            "torchtune                                0.6.1\n",
            "torchvision                              0.24.0+cu128\n"
          ]
        }
      ],
      "source": [
        "#listar librerias pytorch\n",
        "!pip list | grep torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSYRTg84v09F",
        "outputId": "35ff2e9e-6928-4211-fef2-5efa0b3bfa71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Feb 19 00:54:38 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0             28W /   70W |     107MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A             290      C   /usr/bin/python3                        104MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTXKB0OzENbA"
      },
      "source": [
        "##Operaciones Básicas con TensorFlow\n",
        "\n",
        "Una de las principales características de TensorFlow es su capacidad para realizar cálculos con tensores, que son estructuras de datos similares a matrices o arrays. A continuación, veremos cómo crear tensores básicos y realizar operaciones matemáticas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_MFj7rEBGEc",
        "outputId": "b2da4faa-ffa1-4e8c-a6a4-5f8b01e038c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor:\n",
            " tf.Tensor(\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
            "Forma: (2, 3)\n",
            "Tipo de datos: <dtype: 'float32'>\n",
            "Tipo de tensor <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Crear un tensor bidimensional\n",
        "x = tf.constant([[1., 2., 3.],\n",
        "                 [4., 5., 6.]])\n",
        "\n",
        "# Mostrar el tensor, su forma y tipo de datos\n",
        "print(\"Tensor:\\n\", x)\n",
        "print(\"Forma:\", x.shape)\n",
        "print(\"Tipo de datos:\", x.dtype)\n",
        "print(\"Tipo de tensor\", type(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T49lZb0Hw4M9",
        "outputId": "b45d583a-7401-43bf-9aad-5f19b6dc5c00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 2., 3.],\n",
              "       [4., 5., 6.]], dtype=float32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05MlefuFh6Do",
        "outputId": "e3682abc-2576-4aa8-8069-2514df55f63f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "arreglo=np.array([[1,2,3],[4,5,6]])\n",
        "type(arreglo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6ytGS7EDbUt"
      },
      "source": [
        "##Operaciones Matemáticas con Tensores\n",
        "\n",
        "TensorFlow permite realizar operaciones estándar sobre tensores, además de operaciones especializadas en aprendizaje automático. Veamos algunos ejemplos básicos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96syVTQGDbip",
        "outputId": "60d471b1-8385-4ef2-e345-01e8d264d912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Suma de tensores:\n",
            " tf.Tensor(\n",
            "[[ 2.  4.  6.]\n",
            " [ 8. 10. 12.]], shape=(2, 3), dtype=float32)\n",
            "-------------------------------------------------------------------------------- \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Operaciones aritméticas\n",
        "print(\"Suma de tensores:\\n\", x + x)\n",
        "print(\"-\"*80,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ecj9f_2lWmX",
        "outputId": "e2596463-ca1d-4828-ffe9-12a77ddd55fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resta de tensores:\n",
            " tf.Tensor(\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]], shape=(2, 3), dtype=float32)\n",
            "-------------------------------------------------------------------------------- \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Resta de tensores:\\n\", x - x)\n",
        "print(\"-\"*80,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOfUaRp_lcPm",
        "outputId": "146bdcdc-0b85-4cce-d4b7-2ac29b4fc77e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multiplicación por escalar:\n",
            " tf.Tensor(\n",
            "[[ 5. 10. 15.]\n",
            " [20. 25. 30.]], shape=(2, 3), dtype=float32) \n",
            "\n",
            "-------------------------------------------------------------------------------- \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Multiplicación por escalar:\\n\", 5 * x,\"\\n\")\n",
        "print(\"-\"*80,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g6QX8urRaCZ",
        "outputId": "e0048056-2e00-42f4-e737-5ab5acd9af08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Producto matricial:\n",
            " tf.Tensor(\n",
            "[[1. 4.]\n",
            " [2. 5.]\n",
            " [3. 6.]], shape=(3, 2), dtype=float32) \n",
            "\n",
            "-------------------------------------------------------------------------------- \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# LA transpuesta\n",
        "resultado = tf.transpose(x)\n",
        "print(\"Producto matricial:\\n\", resultado,\"\\n\")\n",
        "print(\"-\"*80,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psYa90I_ljAg",
        "outputId": "fa950ee2-b162-4ed2-92c4-a9bb2b09bd03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Producto matricial:\n",
            " tf.Tensor(\n",
            "[[14. 32.]\n",
            " [32. 77.]], shape=(2, 2), dtype=float32) \n",
            "\n",
            "-------------------------------------------------------------------------------- \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Producto matricial (operador '@')\n",
        "resultado = x @ tf.transpose(x)\n",
        "print(\"Producto matricial:\\n\", resultado,\"\\n\")\n",
        "print(\"-\"*80,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ6-RDijlrF5",
        "outputId": "a089e509-d383-485e-c5a8-776a1a9dbbe8"
      },
      "outputs": [],
      "source": [
        "# Concatenación de tensores\n",
        "concatenado = tf.concat([x, x, x], axis=0)\n",
        "print(\"Tensor concatenado:\\n\", concatenado,\"\\n\")\n",
        "print(\"-\"*80,\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G6GNZj4juMU",
        "outputId": "566eba2a-587c-4771-952b-6dc06824766c"
      },
      "outputs": [],
      "source": [
        "#concatenar x, con x**2, X**3, por las columnas\n",
        "concatenado = tf.concat([x, x**2, x**3], axis=1)\n",
        "print(\"Tensor concatenado:\\n\", concatenado,\"\\n\")\n",
        "print(\"-\"*80,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk95sHTDkQxt",
        "outputId": "e02f5d65-bf08-42b7-bf44-979634beb4b7"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JwSqZYXSWpg",
        "outputId": "576d6f8c-3c0f-49b8-c2d3-75deaf2596c6"
      },
      "outputs": [],
      "source": [
        "#media por sample\n",
        "media = tf.reduce_mean(x, axis=1)\n",
        "print(\"Media por sample:\\n\", media,\"\\n\")\n",
        "print(\"-\"*80,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrdY7QGSSeCl",
        "outputId": "2aa01bad-01e2-4576-e1bb-dc1837ff688a"
      },
      "outputs": [],
      "source": [
        "# Media por feature (columna)\n",
        "mean_features = tf.reduce_mean(x, axis=0)\n",
        "print(\"Media por feature:\", mean_features.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy7nmafA0Q43",
        "outputId": "922742e1-2c5c-40cc-a45f-1355a1a586d0"
      },
      "outputs": [],
      "source": [
        "#crear el tensor lalamdo \"tensor\" de [[1.,4.,0.5,2],[2.,3.,1.,0.],[2.,4.,1.,2.]]\n",
        "tensor=tf.constant([[1.,4.,0.5,2],[2.,3.,1.,0.],[2.,4.,1.,2.]])\n",
        "print(\"Tensor:\\n\", tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsjIR9ys1weF",
        "outputId": "12e60061-3e41-4cea-e7cf-226a216f084a"
      },
      "outputs": [],
      "source": [
        "tensorr=tensor**(0.5)\n",
        "print(\"Tensor:\\n\", tensorr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3E1ueF718V9",
        "outputId": "1d5d5d41-b5b5-460a-8a7c-c75de92cd6c5"
      },
      "outputs": [],
      "source": [
        "tensorsuma=tensor+tensorr\n",
        "print(\"Tensor:\\n\", tensorsuma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y47odhIU2Ik9",
        "outputId": "c052d872-4ea9-46f4-e7d0-5896a6ca238b"
      },
      "outputs": [],
      "source": [
        "tensorcon=tf.concat([tensor,tensorr,tensorsuma],axis=0)\n",
        "print(\"Tensor:\\n\", tensorcon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWVJeO2I2dSV",
        "outputId": "40bebaee-c746-4c4f-e63f-93fe654ce5de"
      },
      "outputs": [],
      "source": [
        "respuesta=tf.concat([(tensorcon,tensorcon)],axis=1)\n",
        "print(\"Tensor:\\n\", respuesta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKZx5L1N3iXN",
        "outputId": "36d1560c-0741-44a9-e685-b8e487c0c801"
      },
      "outputs": [],
      "source": [
        "tensorcon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip_K_QVg3q_V",
        "outputId": "44f72d42-99a1-4a4d-bced-54373773550b"
      },
      "outputs": [],
      "source": [
        "sumah=tf.reduce_sum(tensorcon,axis=1)\n",
        "print(\"Tensor:\\n\", sumah)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJsu95nf34Lc",
        "outputId": "f56fcc3e-6308-4e18-c9b9-da2c8c0d1c81"
      },
      "outputs": [],
      "source": [
        "mediah=tf.reduce_mean(tensorcon,axis=1)\n",
        "print(\"Tensor:\\n\", mediah)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnd7d89w4APO",
        "outputId": "3abcd729-9df8-469b-bd6f-9d185486e1a6"
      },
      "outputs": [],
      "source": [
        "sumav=tf.reduce_sum(tensorcon,axis=0)\n",
        "print(\"Tensor:\\n\", sumav)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRSU175d4H9d",
        "outputId": "af56fbe4-2d7c-4afb-e736-681b18f956fd"
      },
      "outputs": [],
      "source": [
        "mediav=tf.reduce_mean(tensorcon,axis=0)\n",
        "print(\"Tensor:\\n\", mediav)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZNY_zIDziBJ"
      },
      "source": [
        "# Concepto de sigmoide y softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjZ9cbj5TWIA"
      },
      "source": [
        "![](https://www.researchgate.net/publication/325856086/figure/fig1/AS:723221292789765@1549440801787/Softmax-function-image.png)\n",
        "\n",
        "\n",
        "# Softmax explicado paso a paso\n",
        "\n",
        "##  ¿Qué es Softmax?\n",
        "\n",
        "Softmax es una función que transforma un vector de números reales en un vector de **probabilidades** que suman 1.  \n",
        "Se usa mucho en **clasificación multiclase**, porque permite interpretar las salidas de un modelo como probabilidades de cada clase.  \n",
        "\n",
        "Si tienes un vector $(z = [z_1, z_2, ..., z_n])$, el Softmax se define así:\n",
        "\n",
        "$sigma(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}$\n",
        "\n",
        "\n",
        "Donde:\n",
        "\n",
        "- $(e^{z_i})$ es la exponencial de cada elemento.\n",
        "- El denominador $(\\sum_{j=1}^{n} e^{z_j})$ normaliza para que la suma sea 1.\n",
        "\n",
        "---\n",
        "\n",
        "## 2 Ejemplo paso a paso\n",
        "\n",
        "Supongamos que tenemos un vector:\n",
        "\n",
        "\n",
        "$z = [2.0, 1.0, 0.1]$\n",
        "\n",
        "\n",
        "**Paso 1: Calcular la exponencial de cada elemento**\n",
        "\n",
        "$e^z = [e^2.0, e^1.0, e^{0.1}] \\approx [7.389, 2.718, 1.105]$\n",
        "\n",
        "\n",
        "**Paso 2: Sumar todas las exponenciales**\n",
        "${suma} = 7.389 + 2.718 + 1.105 \\approx 11.212$\n",
        "\n",
        "\n",
        "**Paso 3: Dividir cada exponencial por la suma**\n",
        "\n",
        "${Softmax}(z) = \\left[\\frac{7.389}{11.212}, \\frac{2.718}{11.212}, \\frac{1.105}{11.212}\\right] \\approx [0.659, 0.242, 0.099]$\n",
        "\n",
        " Ahora tenemos un vector de **probabilidades** que suman 1.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PsJZ6zBsBht",
        "outputId": "d7cbefd7-9dc8-4f59-d8b6-05e47b982765"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXY1W6MqlyqB",
        "outputId": "3687b375-6404-40ed-e9ad-8bfe61731277"
      },
      "outputs": [],
      "source": [
        "# Aplicación de una función matemática: Softmax\n",
        "softmax = tf.nn.softmax(x, axis=1)\n",
        "print(\"Softmax aplicado al tensor:\\n\", softmax,\"\\n\")\n",
        "print(\"-\"*80,\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqp0UP8fmBUI",
        "outputId": "a5b3a19e-0985-45b4-9e5a-b65511e418cb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Reducción: suma total de los elementos del tensor\n",
        "suma_total = tf.reduce_sum(x)\n",
        "print(\"Suma total del tensor:\", suma_total.numpy())\n",
        "suma_total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKgCfv4VBovI"
      },
      "source": [
        "##Ejecución en GPU\n",
        "TensorFlow puede aprovechar GPUs para acelerar los cálculos.\n",
        "\n",
        "Si está usando Google Colab, vaya a menu a ***Entorno de ejecución ***y luego ingrese a ***Cambiar tipo de Entorno de Ejecución*** y luego seleccione ***T4 GPU ***. Debe ejecutar todas las celdas anteriores.\n",
        "\n",
        "\n",
        "Verifica si tu sistema está utilizando una GPU con este código:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztL4azmsGivX",
        "outputId": "0ecebc2f-bf3d-4b90-99a5-308f8e037a39"
      },
      "outputs": [],
      "source": [
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"TensorFlow está utilizando la GPU\")\n",
        "else:\n",
        "    print(\"TensorFlow no está utilizando la GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5Dl52ltHchh"
      },
      "source": [
        "##Variables en TensorFlow\n",
        "Mientras que los tensores normales son inmutables, las variables (tf.Variable) permiten almacenar valores que se pueden modificar, como los pesos de un modelo. Aquí tienes un ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO5igk0YHcz_",
        "outputId": "2896f605-ee55-48af-a2cd-2a4304be3797"
      },
      "outputs": [],
      "source": [
        "# Crear una variable\n",
        "var = tf.Variable([0.0, 0.0, 0.0])\n",
        "\n",
        "# Asignar nuevos valores\n",
        "var.assign([1, 2, 3])\n",
        "print(\"Variable actualizada:\", var.numpy())\n",
        "\n",
        "# Incrementar valores de la variable\n",
        "var.assign_add([1, 1, 1])\n",
        "print(\"Variable incrementada:\", var.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcG_YOstH5w3"
      },
      "source": [
        "# Diferenciación Automática  (Repaso de conceptos)\n",
        "La diferenciación automática permite calcular derivadas de manera eficiente. Este mecanismo es esencial para entrenar modelos utilizando optimizadores como el descenso de gradiente.\n",
        "\n",
        "## Calcular derivadas con TensorFlow: Explicación\n",
        "\n",
        "##  Variables\n",
        "\n",
        "- En TensorFlow, se usan **variables** (`tf.Variable`) para valores que pueden cambiar y respecto a los cuales queremos derivar.\n",
        "- Las variables son necesarias para que TensorFlow pueda **rastrear dependencias** y calcular gradientes automáticamente.\n",
        "\n",
        "---\n",
        "\n",
        "##  Definir la función\n",
        "\n",
        "- La función que queremos derivar puede ser cualquier expresión matemática, como un polinomio o la función de pérdida de un modelo.\n",
        "- Por ejemplo, un polinomio:\n",
        "$\n",
        "f(x) = 3x^3 + 2x^2 - 4x - 2\n",
        "$\n",
        "\n",
        "- TensorFlow graba las operaciones sobre las variables para poder calcular cómo cada salida depende de sus entradas.\n",
        "\n",
        "---\n",
        "\n",
        "##  `tf.GradientTape`\n",
        "\n",
        "- `GradientTape` es un contexto que **graba todas las operaciones** realizadas sobre variables dentro de su bloque.\n",
        "- Esto permite a TensorFlow **construir automáticamente un grafo de derivación** para calcular gradientes.\n",
        "\n",
        "---\n",
        "\n",
        "##  Calcular el gradiente\n",
        "\n",
        "- Una vez que la función ha sido evaluada dentro del `GradientTape`, podemos pedir a TensorFlow que calcule la **derivada de la salida respecto a la variable**.\n",
        "- Matemáticamente, para nuestro polinomio:\n",
        "$\n",
        "f'(x) = \\frac{d}{dx}(3x^3 + 2x^2 - 4x - 2) = 9x^2 + 4x - 4\n",
        "$\n",
        "- Evaluando en $(x = 2)$:\n",
        "\n",
        "$\n",
        "f'(2) = 9(2^2) + 4(2) - 4 = 40\n",
        "$\n",
        "\n",
        "---\n",
        "\n",
        "##  Interpretación\n",
        "\n",
        "- El gradiente obtenido indica **la tasa de cambio de la función respecto a la variable**.\n",
        "- En aprendizaje automático, esto se usa para **actualizar los parámetros de un modelo** durante el entrenamiento.\n",
        "\n",
        "---\n",
        "\n",
        "## Resumen conceptual\n",
        "\n",
        "1. Se definen **variables** sobre las que queremos derivar.\n",
        "2. `GradientTape` **graba operaciones** para calcular gradientes automáticamente.\n",
        "3. `tape.gradient` calcula la **derivada** de la salida respecto a las variables.\n",
        "4. El resultado es un **tensor que indica la pendiente** de la función en ese punto.\n",
        "5. Esta técnica se usa ampliamente en **optimización y entrenamiento de redes neuronales**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "LFb6GxKADUaq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def f(x):\n",
        "    return 3*x**3 + 2*x**2-4*x - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "KiueLhAGDaH5",
        "outputId": "891be7eb-7e38-41fb-fd3e-2ebc76fbf045"
      },
      "outputs": [],
      "source": [
        "#Grafico de dispersión entre a y y donde x\n",
        "import matplotlib.pyplot as plt\n",
        "a = tf.linspace(-10, 10, 100)\n",
        "y = f(a)\n",
        "plt.scatter(a, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IC09wo5st-Q"
      },
      "source": [
        "# Derivadas de la función\n",
        "\n",
        "## Función original\n",
        "\n",
        "$$\n",
        "f(x) = 3x^3 + 2x^2 - 4x - 2\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "##  Paso 1: Primera derivada\n",
        "\n",
        "Aplicamos reglas de derivación:\n",
        "\n",
        "$$\n",
        "f'(x) = \\frac{d}{dx}\\left(3x^3 + 2x^2 - 4x - 2\\right)\n",
        "$$\n",
        "\n",
        "- Derivada de $(3x^3 \\;\\rightarrow\\; 9x^2)$  \n",
        "- Derivada de $(2x^2 \\;\\rightarrow\\; 4x)$  \n",
        "- Derivada de $(-4x \\;\\rightarrow\\; -4)$\n",
        "- Derivada de $(-2 \\;\\rightarrow\\; 0)$  \n",
        "\n",
        "$$\n",
        "f'(x) = 9x^2 + 4x - 4\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "##  Paso 2: Segunda derivada\n",
        "\n",
        "Ahora derivamos otra vez:\n",
        "\n",
        "$$\n",
        "f''(x) = \\frac{d}{dx}\\left(9x^2 + 4x - 4\\right)\n",
        "$$\n",
        "\n",
        "- Derivada de $(9x^2 \\;\\rightarrow\\; 18x)$  \n",
        "- Derivada de $(4x \\;\\rightarrow\\; 4)$  \n",
        "- Derivada de $(-4 \\;\\rightarrow\\; 0)$  \n",
        "\n",
        "$$\n",
        "f''(x) = 18x + 4\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "##  Resumen\n",
        "\n",
        "- **Función original:**\n",
        "\n",
        "$$\n",
        "f(x) = 3x^3 + 2x^2 - 4x - 2\n",
        "$$\n",
        "\n",
        "- **Primera derivada (pendiente):**\n",
        "\n",
        "$$\n",
        "f'(x) = 9x^2 + 4x - 4\n",
        "$$\n",
        "\n",
        "- **Segunda derivada (curvatura):**\n",
        "\n",
        "$$\n",
        "f''(x) = 18x + 4\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUAyFjKvvLZO"
      },
      "source": [
        "##GrandientTape de TensorFlow\n",
        "Es una cinta de grabación (\"tape\") que observa todas las operaciones matemáticas realizadas sobre las variables marcadas como tf.Variable.\n",
        "\n",
        "Luego, podemos pedirle que calcule las derivadas de una expresión con respecto a esas variables.\n",
        "\n",
        "Se llama \"tape\" porque funciona como una grabadora:\n",
        "\n",
        "Graba las operaciones (por ejemplo, multiplicaciones, potencias, sumas...).\n",
        "\n",
        "Reproduce hacia atrás para aplicar la regla de la cadena y obtener derivadas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uphy_ukGsJXR",
        "outputId": "e2cbf66e-e85a-407d-df50-0e286672213a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = tf.Variable(7.5)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = f(x)   # f(x) = x³+....\n",
        "\n",
        "# Pedimos la derivada de y respecto a x\n",
        "dy_dx = tape.gradient(y, x)\n",
        "\n",
        "print(\"f(x) =\", y.numpy())        #\n",
        "print(\"f'(x) =\", dy_dx.numpy())   #\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xs7Daw-XwAI3"
      },
      "source": [
        "# Diferencia entre usar GradientTape y luego llamar a tape.gradient\n",
        "\n",
        "## with tf.GradientTape() as tape:\n",
        "\n",
        "En el ejemplo anterior creamos la cinta (el “grabador”).\n",
        "\n",
        "Durante ese bloque, TensorFlow observa todas las operaciones matemáticas que se hacen con variables (tf.Variable).\n",
        "\n",
        "Es como si grabara paso a paso cómo se calculó la función.\n",
        "\n",
        "## tape.gradient(y, x)\n",
        "\n",
        "Una vez finaliza el bloque, usamos esa cinta para pedir la derivada de una salida y respecto a una variable x.\n",
        "\n",
        "Aquí la cinta reproduce en reversa las operaciones grabadas (regla de la cadena).\n",
        "\n",
        "Resultado: la derivada numérica en el punto actual de x."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7HBlBrCwQy8"
      },
      "source": [
        "# Primera y segunda derivada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFLtEmkGH5-V",
        "outputId": "adf3f8fd-9db0-49cf-8f43-fc5d4a891ba3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Definimos la función f(x) = 3x³ + 2x² - 4x - 2\n",
        "def f(x):\n",
        "    return 3*x**3 + 2*x**2 - 4*x - 2\n",
        "\n",
        "# Definimos 'x' como una variable (TensorFlow necesita una Variable para calcular derivadas).\n",
        "x = tf.Variable(0.481)\n",
        "\n",
        "# Usamos dos \"GradientTape\":\n",
        "# - El primero (tape2) calculará la PRIMERA derivada de f(x) con respecto a x.\n",
        "# - El segundo (tape) observará lo que hace el primero, para luego calcular la SEGUNDA derivada.\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    with tf.GradientTape() as tape2:\n",
        "        # Evaluamos la función dentro de ambas cintas.\n",
        "        y = f(x)\n",
        "\n",
        "    # PRIMERA DERIVADA: f'(x)\n",
        "    # La primera derivada mide la pendiente de la función en un punto.\n",
        "    # En términos prácticos: indica la velocidad de cambio de f(x) con respecto a x.\n",
        "    g_x = tape2.gradient(y, x)\n",
        "\n",
        "# SEGUNDA DERIVADA: f''(x)\n",
        "# La segunda derivada mide cómo cambia la pendiente.\n",
        "# En términos prácticos:\n",
        "#   - Si f''(x) > 0 → la curva es cóncava hacia arriba (mínimos locales).\n",
        "#   - Si f''(x) < 0 → la curva es cóncava hacia abajo (máximos locales).\n",
        "g_x2 = tape.gradient(g_x, x)\n",
        "\n",
        "print(\"x =\", x.numpy())\n",
        "print(\"f(x) =\", y.numpy())\n",
        "print(\"f'(x) =\", g_x.numpy())\n",
        "print(\"f''(x) =\", g_x2.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V1NkGvAwpVq"
      },
      "source": [
        "# Quiero Ver las funciones o las ecuaciones de la derivada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXQfmnDKwoBi",
        "outputId": "f392bec3-eff6-411b-ad75-9774cd3aad15"
      },
      "outputs": [],
      "source": [
        "import sympy as sp\n",
        "\n",
        "# Definir la variable simbólica\n",
        "x = sp.Symbol('x')\n",
        "\n",
        "# Definir la función\n",
        "f = 3*x**3 + 2*x**2 - 4*x - 2\n",
        "\n",
        "# Primera derivada\n",
        "f_prime = sp.diff(f, x)\n",
        "\n",
        "# Segunda derivada\n",
        "f_second = sp.diff(f_prime, x)\n",
        "\n",
        "print(\"Función original f(x):\", f)\n",
        "print(\"Primera derivada f'(x):\", f_prime)\n",
        "print(\"Segunda derivada f''(x):\", f_second)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "OIH3DIZZw-KY",
        "outputId": "fda1c7d1-6323-4343-9ec6-af3ed7fca075"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Definir la función\n",
        "def f(x):\n",
        "    return 3*x**3 + 2*x**2 - 4*x - 2\n",
        "\n",
        "# Definir el rango de valores para x\n",
        "x_vals = np.linspace(-3, 3, 200)\n",
        "f_vals = f(x_vals)\n",
        "\n",
        "# Usamos TensorFlow para obtener derivadas automáticas\n",
        "x = tf.Variable(x_vals)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    with tf.GradientTape() as tape2:\n",
        "        y = f(x)\n",
        "    f_prime = tape2.gradient(y, x)   # primera derivada\n",
        "f_second = tape.gradient(f_prime, x) # segunda derivada\n",
        "\n",
        "# Convertir resultados a numpy para graficar\n",
        "f_prime_vals = f_prime.numpy()\n",
        "f_second_vals = f_second.numpy()\n",
        "\n",
        "# Graficar\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(x_vals, f_vals, label=\"f(x)\", linewidth=2)\n",
        "plt.plot(x_vals, f_prime_vals, label=\"f'(x)\", linestyle=\"--\", linewidth=2)\n",
        "plt.plot(x_vals, f_second_vals, label=\"f''(x)\", linestyle=\":\", linewidth=2)\n",
        "\n",
        "plt.axhline(0, color=\"black\", linewidth=0.7)\n",
        "plt.axvline(0, color=\"black\", linewidth=0.7)\n",
        "plt.legend()\n",
        "plt.title(\"Función, Primera derivada y Segunda derivada\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBupAC6nE-70"
      },
      "source": [
        "##Grafos y funciones\n",
        "\n",
        "En el contexto de TensorFlow, graph se asocia más comúnmente con gráfos porque describe una secuencia de operaciones que puede ser visualizada o ejecutada. Sin embargo, no se refiere específicamente a una imagen o gráficas de matplotlib o seaborn.\n",
        "\n",
        "* @tf.function:\n",
        "\n",
        "Este decorador convierte una función de Python en un gráfo computacional de TensorFlow (un Graph).\n",
        "\n",
        "Las funciones convertidas con @tf.function son más eficientes porque optimizan las operaciones y permiten ejecutar cálculos en diferentes dispositivos como CPUs, GPUs o TPUs.\n",
        "\n",
        "* print('Tracing.\\n'):\n",
        "\n",
        "Este mensaje se imprime solo cuando se crea o se \"traza\" el gráfo computacional por primera vez.\n",
        "Una vez que el gráfo está trazado, las ejecuciones posteriores de la función no vuelven a imprimir el mensaje porque ya se usa el gráfo optimizado.\n",
        "\n",
        "\n",
        "* return tf.reduce_sum(x):\n",
        "\n",
        "Calcula la suma de todos los elementos del tensor x.\n",
        "\n",
        "tf.reduce_sum es una operación que \"reduce\" un tensor a un solo valor al aplicar la suma en todas las dimensiones.\n",
        "\n",
        "**Tracing**\n",
        "Cuando se llama por primera vez a una función decorada con @tf.function, TensorFlow analiza (\"traza\") el código para crear un grafo computacional.\n",
        "\n",
        "Este grafo permite realizar optimizaciones y ejecutar la función de manera más eficiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "fRxMvI7hF9SU"
      },
      "outputs": [],
      "source": [
        "# Decorador de TensorFlow que convierte la función en un \"graph function\"\n",
        "# Esto significa que TensorFlow optimiza la ejecución al compilarla en un grafo computacional.\n",
        "@tf.function\n",
        "def my_func(x):\n",
        "    # Este print se ejecutará SOLO la primera vez que TensorFlow \"tracea\"\n",
        "    # (construye el grafo de operaciones).\n",
        "    print('Tracing.\\n')\n",
        "\n",
        "    # tf.reduce_sum suma todos los elementos de x (tensor o array)\n",
        "    return tf.reduce_sum(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx5ZOhLRGLki",
        "outputId": "7c58e5c8-96c3-4a45-cd68-93b4bd6ea0f0"
      },
      "outputs": [],
      "source": [
        "x = tf.constant([1, 2, 3])\n",
        "my_func(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhwkmT94pl6m",
        "outputId": "b303212d-2eee-4f78-fa20-2f6b1278cd53"
      },
      "outputs": [],
      "source": [
        "my_func(x).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOe_FOvUGMkM"
      },
      "source": [
        "En llamadas posteriores, TensorFlow solo ejecuta el gráfo optimizado, omitiendo cualquier paso que no sea de TensorFlow. A continuación, observa que my_func no imprime el seguimiento, ya que print es una función de Python, no una función de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXQCpFvFGaP9",
        "outputId": "a81efc51-8a84-4efd-a21a-7f7820b936d4"
      },
      "outputs": [],
      "source": [
        "x = tf.constant([10, 9, 8])\n",
        "my_func(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieS_bEnep8mQ",
        "outputId": "c51d2b8f-c8ff-4e87-8d82-287fb4058b75"
      },
      "outputs": [],
      "source": [
        "my_func(x).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z5YbIC6HGza"
      },
      "source": [
        "Un gráfo puede no ser reutilizable para entradas con una forma diferente (forma y tipo de datos), por lo que se genera un nuevo gráfo en su lugar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofg04kW-HH_B",
        "outputId": "9e7ef746-f7bb-44fb-fa78-986413f195f7"
      },
      "outputs": [],
      "source": [
        "x = tf.constant([10.0, 9.1, 8.2], dtype=tf.float32)\n",
        "my_func(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g84yVFMqL0w",
        "outputId": "32613132-50fb-4545-a373-1d8385d6aec5"
      },
      "outputs": [],
      "source": [
        "my_func(x).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvd9Vez2H1E_"
      },
      "source": [
        "Estos gráfos capturados ofrecen dos beneficios:\n",
        "\n",
        "1. En muchos casos, proporcionan una aceleración significativa en la ejecución (aunque no en este ejemplo trivial).\n",
        "\n",
        "2. Puedes exportar estos gráfo, utilizando tf.saved_model, para ejecutarlos en otros sistemas, como un servidor o un dispositivo móvil, sin necesidad de instalar Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgL98cHwIh1e"
      },
      "source": [
        "##Módulos, capas y modelos.\n",
        "\n",
        "tf.Module es una clase para administrar sus objetos tf.Variable y los objetos tf.function que operan en ellos. La clase tf.Module es necesaria para admitir dos funciones importantes:\n",
        "\n",
        "\n",
        "Puede guardar y restaurar los valores de sus variables usando tf.train.Checkpoint . Esto es útil durante el entrenamiento, ya que es rápido guardar y restaurar el estado de un modelo.\n",
        "Puede importar y exportar los valores de tf.Variable y los gráfos de tf.function usando tf.saved_model . Esto le permite ejecutar su modelo independientemente del programa de Python que lo creó.\n",
        "\n",
        "Aquí hay un ejemplo completo exportando un objeto tf.Module simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "saciEDFfIoBk"
      },
      "outputs": [],
      "source": [
        "class MyModule(tf.Module):\n",
        "    \"\"\"\n",
        "    Una clase que extiende `tf.Module` para demostrar cómo gestionar variables y funciones en TensorFlow.\n",
        "\n",
        "    Atributos:\n",
        "        weight (tf.Variable): Una variable que almacena un valor inicializado durante la creación del módulo.\n",
        "\n",
        "    Métodos:\n",
        "        multiply(x):\n",
        "            Realiza una multiplicación entre la entrada `x` y la variable `weight`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, value):\n",
        "        \"\"\"\n",
        "        Constructor de la clase MyModule.\n",
        "\n",
        "        Args:\n",
        "            value (float o int): Valor inicial para la variable `weight`.\n",
        "        \"\"\"\n",
        "        self.weight = tf.Variable(value)\n",
        "\n",
        "    @tf.function\n",
        "    def multiply(self, x):\n",
        "        \"\"\"\n",
        "        Multiplica la entrada `x` por la variable `weight`.\n",
        "\n",
        "        Args:\n",
        "            x (tf.Tensor): Un tensor que representa los valores de entrada.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: El resultado de la multiplicación de `x` y `weight`.\n",
        "        \"\"\"\n",
        "        return x * self.weight\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ1IYaKzJZeG"
      },
      "source": [
        " El siguiente código ejecuta una operación de multiplicación elemento por elemento entre el tensor de entrada y el valor almacenado en la variable weight del módulo. En este caso, el resultado es el tensor [3, 6, 9].\n",
        "\n",
        "1. Creamos una instancia de la clase MyModule con el valor inicial de weight igual a 3. Esto significa que el atributo weight será una variable de TensorFlow (tf.Variable) con un valor inicial de 3.\n",
        "\n",
        "2. Llamamos al método multiply de la instancia mod pasando un tensor constante de valores [1, 2, 3].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlW3lUBBJQrb",
        "outputId": "663ae1dd-11c9-45c9-fad5-8e2549bc9b16"
      },
      "outputs": [],
      "source": [
        "mod = MyModule(3)\n",
        "mod.multiply(tf.constant([1, 2, 3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtYlwEJdqg3C",
        "outputId": "26fc5e3d-0785-4eec-87fc-6fddcd3e8f9c"
      },
      "outputs": [],
      "source": [
        "mod.multiply(tf.constant([1, 2, 3])).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59V4om0SJD4-"
      },
      "source": [
        "##Salvar el módulo\n",
        "\n",
        "Para guardar un módulo en TensorFlow, se usa la función tf.saved_model.save. Este método permite exportar un módulo o modelo de TensorFlow, junto con sus variables y gráficos, para ser reutilizado en otros entornos sin necesidad de depender del programa original de Python.\n",
        "\n",
        "![image](https://github.com/adiacla/bigdata/blob/master/modulosTF.JPG?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "1X-Jp55UJ6XD"
      },
      "outputs": [],
      "source": [
        "save_path = './saved'\n",
        "tf.saved_model.save(mod, save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrQYtPJ3Kh4B"
      },
      "source": [
        "El modelo guardado resultante es independiente del código que lo creó. Puede cargar un modelo guardado desde Python, otros enlaces de idioma o TensorFlow Serving . También puede convertirlo para que se ejecute con TensorFlow Lite o TensorFlow JS ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqZfweFSKhJd",
        "outputId": "3579fbeb-1861-44cd-d782-1014f48bf0f8"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load(save_path)\n",
        "reloaded.multiply(tf.constant([4, 5, 6])).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOoqi51qIh-k"
      },
      "source": [
        "##Creación de Modelos y Entrenamiento- Bucles de entrenamiento\n",
        "\n",
        "Ahora vamos a poner todo unido para construir un modelo básico y entrénarlo desde cero.\n",
        "\n",
        "1. Crear algunos datos de ejemplo. Esto genera una nube de puntos que sigue vagamente una curva cuadrática:\n",
        "\n",
        "2. Definir modelos personalizados usando tf.keras.Model y entrenarlos manualmente o con utilidades como Model.fit.\n",
        "\n",
        "Vamos a realizar un ejemplo  de un modelo entrenado para ajustar datos sinteticos o simulados:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "8TnrOmoQIqR_"
      },
      "outputs": [],
      "source": [
        "# Importa la biblioteca principal de Matplotlib\n",
        "import matplotlib\n",
        "\n",
        "# Importa el módulo pyplot de Matplotlib y lo asigna al alias 'plt'\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Configura el tamaño predeterminado de las figuras generadas por Matplotlib\n",
        "# Esto asegura que todas las gráficas creadas tengan dimensiones de 9 pulgadas de ancho por 6 pulgadas de alto\n",
        "matplotlib.rcParams['figure.figsize'] = [9, 6]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNxwYO4lL3nl"
      },
      "source": [
        "#Generación de datos aleatorios (sintéticos) a partir de una función\n",
        "\n",
        "Se genera un conjunto de datos x y se calcula y usando una función cuadrática, a la cual se añade ruido para simular datos experimentales o del mundo real.\n",
        "\n",
        "* Visualización:\n",
        "Los puntos (Data) muestran los datos con ruido.\n",
        "\n",
        "La línea (Ground truth) representa la relación teórica exacta entre x e y sin ruido.\n",
        "\n",
        "* Leyenda: Facilita identificar qué serie corresponde a los datos simulados y cuál a la función teórica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBmCjqXkMOUI"
      },
      "source": [
        "Explicaciones del código\n",
        "\n",
        "1. tf.linspace(-2, 2, 201): Genera 201 puntos equidistantes entre -2 y 2, lo que crea un vector de entradas x.\n",
        "2. tf.cast(x, tf.float32): Asegura que los valores de x sean del tipo float32 para ser utilizados en operaciones de TensorFlow.\n",
        "3. Función f(x): Calcula el valor de la ecuación cuadrática $f(x) = x^2 + 2x - 5$ para cada valor en x.\n",
        "4. tf.random.normal(shape=[201]): Añade ruido aleatorio a los valores de y para simular un conjunto de datos ruidosos.\n",
        "\n",
        "\n",
        "##plt.plot:\n",
        "Dibuja dos gráficos, uno con puntos (.) para los datos generados con ruido.\n",
        "Otro con una línea que representa la función cuadrática sin ruido (la \"verdad fundamental\").\n",
        "\n",
        "Al final, el gráfico resultante muestra tanto los datos ruidosos como la función que los genera.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8zbp2rwFoCS"
      },
      "source": [
        "# Creemo un modelo cuadrático paramétrico hecho a mano con Gradiente del descenso (GradientTape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLZoXt4FMd1U",
        "outputId": "3e6d2cb7-7e79-412e-f0b2-ae376380a026"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# Crear un tensor 'x' con valores en un rango de -2 a 2, dividido en 201 puntos\n",
        "x = tf.linspace(-2, 2, 201)  # Genera valores de -2 a 2 con 201 puntos equidistantes\n",
        "# Convertir 'x' a tipo de dato float32 para su procesamiento posterior\n",
        "x = tf.cast(x, tf.float32)\n",
        "x.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "-sNFsdzr3DAq",
        "outputId": "1b7c1018-6842-4b74-8d46-f0cf0c392114"
      },
      "outputs": [],
      "source": [
        "# Definir una función f(x) que calcule el valor de la expresión cuadrática: f(x) = x^2 + 2x - 5\n",
        "def f(x):\n",
        "    y = x**2 + 2*x - 5  # Evaluación de la función cuadrática\n",
        "    return y  # Devolver el valor calculado\n",
        "\n",
        "# Generar el vector de 'y' usando la función f(x) y agregar un ruido aleatorio de media 0 y varianza 1\n",
        "y = f(x) + tf.random.normal(shape=[201])  # Añadir ruido aleatorio a los valores de 'y'\n",
        "\n",
        "# Graficar los datos generados (con ruido) usando puntos ('.') en el gráfico\n",
        "plt.plot(x.numpy(), y.numpy(), '.', label='Data')  # Convertir los tensores a arrays de NumPy para graficar\n",
        "\n",
        "# Graficar la \"verdad fundamental\" (la función sin ruido) con una línea continua\n",
        "plt.plot(x, f(x), label='Ground truth')  # Graficar la función original sin ruido\n",
        "\n",
        "# Añadir la leyenda para explicar las líneas en el gráfico\n",
        "plt.legend()  # Mostrar leyenda para identificar los datos y la verdad fundamental\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiA-YlfUB769",
        "outputId": "85ee0606-89fd-4100-ac51-6af864ac63d5"
      },
      "outputs": [],
      "source": [
        "# Preparamos entradas: [x, x^2]\n",
        "X = tf.stack([x, x**2], axis=1)   # shape = (201, 2)\n",
        "\n",
        "print(\"Forma de X:\", X.shape)\n",
        "print(\"Forma de y:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VOvSs5Lm0hob",
        "outputId": "85905f98-2d65-4592-ef35-6871c8a685a7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a dictionary with the data\n",
        "data_dict = {\n",
        "    'X1': x.numpy(),\n",
        "    'X2': (x**2).numpy(),\n",
        "    'y': y.numpy()\n",
        "}\n",
        "\n",
        "# Create the pandas DataFrame\n",
        "df = pd.DataFrame(data_dict)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSonc40kzeSu"
      },
      "source": [
        "![](https://github.com/adiacla/bigdata/blob/master/perceptron2.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L2Tp5sez6Ef"
      },
      "source": [
        "## Creamos un modelo con pesos y bias aleatorios\n",
        "\n",
        "Veremo como se comparta la función de error si mantenemos constante dos variables y variamos w1. Para explciarl el descenso del gradiente.\n",
        "\n",
        "**El descenso del gradiente (Gradient Descent)** es un algoritmo de optimización que sirve para encontrar los valores de los parámetros (pesos y sesgos en una red neuronal) que minimizan la función de pérdida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "ZulZXdDQxDkY",
        "outputId": "89cfd528-9dd1-4a0b-d808-aaf666335449"
      },
      "outputs": [],
      "source": [
        "# Define the fixed values for bias (b) and weight (w1)\n",
        "b = -5\n",
        "w2 = 1\n",
        "\n",
        "# Define a range of values for w2\n",
        "w1_values = np.linspace(-6, 10, 100)\n",
        "\n",
        "# Initialize a list to store the mean squared errors\n",
        "mse_values = []\n",
        "\n",
        "# Iterate through the w2 values\n",
        "for w1 in w1_values:\n",
        "    # Calculate the new column 'a1'\n",
        "    df['a1'] = b + (w1 * df['X1']) + (w2 * df['X2'])\n",
        "    # Calculate the mean squared error\n",
        "    mse = tf.reduce_mean(tf.square(df['a1'] - df['y']))\n",
        "    mse_values.append(mse.numpy())\n",
        "\n",
        "\n",
        "# Plot the mean squared error against w2\n",
        "plt.plot(w1_values, mse_values)\n",
        "plt.xlabel(\"w1\")\n",
        "plt.ylabel(\"Mean Squared Error\")\n",
        "plt.title(\"Mean Squared Error vs. w2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "p6ZotrF52qiE",
        "outputId": "fef634fe-cccf-4c29-f580-9b76d17a3ea5"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd09_RcdGuXZ"
      },
      "source": [
        "### Modelo\n",
        "\n",
        "La salida del modelo para el ejemplo \\(i\\) es:\n",
        "\n",
        "$\\hat y_i = a1_i = b + w_1 x_{1i} + w_2 x_{2i},\\quad \\text{con } b=-5,\\; w_2=1.$\n",
        "\n",
        "### Pérdida MSE\n",
        "\n",
        "La función de pérdida se define como:\n",
        "\n",
        "$\n",
        "\\mathcal{L}(w_1) = \\frac{1}{n}\\sum_{i=1}^n \\left(b + w_1 x_{1i} + w_2 x_{2i} - y_i\\right)^2$\n",
        "\n",
        "### Derivada de la pérdida respecto a $w_1$\n",
        "\n",
        "$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial w_1}\n",
        "= \\frac{2}{n}\\sum_{i=1}^n \\left(b + w_1 x_{1i} + w_2 x_{2i} - y_i\\right)\\,x_{1i}\n",
        "$\n",
        "\n",
        "### Forma vectorizada\n",
        "\n",
        "$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial w_1}\n",
        "=\\frac{2}{n}\\, X_1^\\top\\left(b\\,\\mathbf{1}+w_1 X_1+w_2 X_2-y\\right)\n",
        "$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sB_JwFdj60f9",
        "outputId": "1b0d8ab7-d2f4-4305-87f2-7c97f835a458"
      },
      "outputs": [],
      "source": [
        "#crea dataframe de (w1_values, mse_values\n",
        "df2 = pd.DataFrame({'w1': w1_values, 'mse': mse_values})\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzFxLZpaHkIq"
      },
      "source": [
        "#Un ejemplo dibujando la linea tagente a un punto de la función de pérdida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "3ea8a009",
        "outputId": "39171213-599b-4205-8868-977adb81efee"
      },
      "outputs": [],
      "source": [
        "# Define the fixed values for bias (b) and weight (w2)\n",
        "b_fixed = tf.constant(-5.0, dtype=tf.float32)\n",
        "w2_fixed = tf.constant(1.0, dtype=tf.float32)\n",
        "\n",
        "# Convert DataFrame columns to TensorFlow tensors\n",
        "X1_tensor = tf.constant(df['X1'].values, dtype=tf.float32)\n",
        "X2_tensor = tf.constant(df['X2'].values, dtype=tf.float32)\n",
        "y_tensor = tf.constant(df['y'].values, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def mse_for_w1(w1):\n",
        "    \"\"\"\n",
        "    Calculates the mean squared error for a given w1, with fixed b and w2.\n",
        "    \"\"\"\n",
        "    a1 = b_fixed + (w1 * X1_tensor) + (w2_fixed * X2_tensor)\n",
        "    mse = tf.reduce_mean(tf.square(a1 - y_tensor))\n",
        "    return mse\n",
        "\n",
        "# Choose the point where w1 = 0\n",
        "w1_point = tf.constant(0.0, dtype=tf.float32)\n",
        "mse_point = mse_for_w1(w1_point) # This should be close to 2 based on the previous plot\n",
        "\n",
        "# Use GradientTape to calculate the gradient of the MSE with respect to w1 at w1_point\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(w1_point)\n",
        "    mse_at_point = mse_for_w1(w1_point)\n",
        "\n",
        "gradient_at_point = tape.gradient(mse_at_point, w1_point)\n",
        "\n",
        "print(f\"Gradient of MSE at w1 = {w1_point.numpy()}: {gradient_at_point.numpy()}\")\n",
        "\n",
        "# Define the tangent line equation: y = m * (x - x1) + y1\n",
        "# (x1, y1) = (w1_point.numpy(), mse_point.numpy())\n",
        "# m = gradient_at_point.numpy()\n",
        "\n",
        "def tangent_line(w, w1_point, mse_point, gradient):\n",
        "    return gradient * (w - w1_point) + mse_point\n",
        "\n",
        "# Generate a range of w1 values for plotting\n",
        "w1_values_plot = np.linspace(-6, 10, 100)\n",
        "\n",
        "# Calculate MSE values for plotting\n",
        "mse_values_plot = [mse_for_w1(tf.constant(w, dtype=tf.float32)).numpy() for w in w1_values_plot]\n",
        "\n",
        "# Calculate tangent line values for plotting\n",
        "tangent_values_plot = tangent_line(w1_values_plot, w1_point.numpy(), mse_point.numpy(), gradient_at_point.numpy())\n",
        "\n",
        "# Plot the MSE curve and the tangent line\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(w1_values_plot, mse_values_plot, label=\"MSE vs. w1\")\n",
        "plt.plot(w1_values_plot, tangent_values_plot, label=f\"Tangent at w1={w1_point.numpy()}\", linestyle='--')\n",
        "plt.scatter([w1_point.numpy()], [mse_point.numpy()], color='red', zorder=5) # Mark the tangent point\n",
        "plt.xlabel(\"w1\")\n",
        "plt.ylabel(\"Mean Squared Error\")\n",
        "plt.title(\"Mean Squared Error vs. w1 with Tangent Line\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSsSlX9oNzn3"
      },
      "source": [
        "## Ahora explicado todo entonces vamos Entrenar el modelo usando Tensorflow (con la class Module)\n",
        "\n",
        "Definición de la clase Model(tf.Module):\n",
        "\n",
        "**tf.Module** es una clase base para crear modelos personalizados en TensorFlow. Permite realizar un seguimiento automático de las variables y asegura que los parámetros del modelo se traten como variables de TensorFlow.\n",
        "\n",
        "* Método __init__(self):\n",
        "\n",
        "*rand_init = tf.random.uniform(shape=[3], minval=0., maxval=5., seed=22)* genera un tensor con 3 valores aleatorios distribuidos uniformemente en el rango [0., 5.].\n",
        "Estos valores se usarán para inicializar los pesos y el sesgo del modelo.\n",
        "\n",
        "*self.w_q, self.w_l y self.b * son variables de TensorFlow que se inicializan con estos valores aleatorios.\n",
        "\n",
        "**self.w_q:** el peso cuadrático correspondiente al término $𝑥2.self.w_l$: el peso lineal correspondiente al término $𝑥.self.b$: el término de sesgo.\n",
        "\n",
        "**Método __call__(self, x)**:\n",
        "\n",
        "Este método hace que la clase sea \"llamable\", es decir, se puede utilizar una instancia de Model como si fuera una función.\n",
        "\n",
        "Toma un tensor de entrada x y calcula la salida del modelo cuadrático utilizando la fórmula:\n",
        "$$y = w_q \\cdot x^{2} + w_l \\cdot x + b$$\n",
        "\n",
        "donde $w_q$, $w_l$ y  $b$ son los parámetros del modelo.\n",
        "\n",
        "**Decorador @tf.function:**\n",
        "\n",
        "El decorador @tf.function convierte el método en un gráfico de TensorFlow, lo que mejora la eficiencia en la ejecución, especialmente cuando se utiliza en GPU o TPU.\n",
        "\n",
        "Esto optimiza el cálculo, haciéndolo más rápido en llamadas repetidas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "GX-swR67PFZ0"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# 2. Definimos el modelo con tf.Module\n",
        "# ============================\n",
        "class Neurona(tf.Module):\n",
        "    \"\"\"\n",
        "    Una sola neurona: y_pred = w1*x + w2*x^2 + b\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, seed=42):\n",
        "        # Inicializamos pesos y bias con distribución normal reproducible\n",
        "        init = tf.random.normal(shape=(2,1), seed=seed)   # 2 entradas -> 1 salida\n",
        "        self.W = tf.Variable(init)   # Matriz de pesos (2x1)\n",
        "        self.b = tf.Variable(tf.zeros(1))  # Sesgo\n",
        "\n",
        "    @tf.function\n",
        "    def __call__(self, X):\n",
        "        # Operación de la neurona (sin activación, lineal)\n",
        "        return tf.matmul(X, self.W) + self.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjviHRw3RnsX"
      },
      "source": [
        "##Definir la función de pérdida:\n",
        "\n",
        "Dado que este modelo está diseñado para predecir valores continuos, el error cuadrático medio (MSE, por sus siglas en inglés) es una buena elección para la función de pérdida. Dado un vector de predicciones, $\\hat{y}$ , y un vector de los valores verdaderos o \"ground truth\", 𝑦, el MSE se define como la media de las diferencias cuadradas entre los valores predichos y los valores reales.\n",
        "\n",
        "$$\n",
        "MSE = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- $ m$ es el número total de muestras.\n",
        "- $\\hat{y}_i$ es la predicción del modelo para la \\( i \\)-ésima muestra.\n",
        "- $y_i$ es el valor real o \"ground truth\" para la \\( i \\)-ésima muestra.\n",
        "-$\\sum $ denota la sumatoria a lo largo de todas las muestras.\n",
        "\n",
        "### Detalle del cálculo:\n",
        "\n",
        "La función `mse_loss` realiza los siguientes pasos:\n",
        "\n",
        "1. **Diferencia entre predicciones y valores reales:**\n",
        "   \n",
        "   $$\n",
        "   (\\hat{y}_i - y_i)\n",
        "   $$\n",
        "\n",
        "2. **Cuadrar las diferencias:**\n",
        "   \n",
        "   $$\n",
        "   (\\hat{y}_i - y_i)^2\n",
        "   $$\n",
        "\n",
        "3. **Promediar las diferencias cuadradas:**\n",
        "\n",
        "   $$\n",
        "   MSE = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2\n",
        "   $$\n",
        "\n",
        "Este es el cálculo del **MSE**, que mide cuán cerca están las predicciones del modelo de los valores reales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "IR4eofku4khn"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# 3. Función de pérdida y optimización\n",
        "# ============================\n",
        "def mse_loss(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU1OLt7_TDKW"
      },
      "source": [
        "##Ciclo de entrenamiento básico para el modelo.\n",
        "\n",
        "El ciclo hará uso de la función de pérdida MSE y sus gradientes con respecto a la entrada para actualizar iterativamente los parámetros del modelo. El uso de mini-lotes para el entrenamiento proporciona tanto eficiencia de memoria como una convergencia más rápida. La API tf.data.Dataset tiene funciones útiles para dividir en lotes y mezclar los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZCU-D4MRE8M",
        "outputId": "afa98001-8055-472b-c6c3-eb99139c36a9"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# 4. Entrenamiento con GradientTape\n",
        "# ============================\n",
        "# Instanciamos el modelo\n",
        "modelo = Neurona(seed=42)\n",
        "\n",
        "# Hiperparámetros\n",
        "epochs = 200\n",
        "learning_rate = 0.05\n",
        "losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = modelo(X)\n",
        "        loss = mse_loss(y_pred, tf.expand_dims(y, axis=1))  # expandimos y a (201,1)\n",
        "\n",
        "    # Calculamos gradientes\n",
        "    grads = tape.gradient(loss, [modelo.W, modelo.b])\n",
        "\n",
        "    # Actualizamos parámetros (descenso del gradiente manual)\n",
        "    modelo.W.assign_sub(learning_rate * grads[0])\n",
        "    modelo.b.assign_sub(learning_rate * grads[1])\n",
        "\n",
        "    losses.append(loss.numpy())\n",
        "    if epoch %5 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss.numpy():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxNQN5tfUQ-s"
      },
      "source": [
        "# 3. Predecir un valor\n",
        "\n",
        "El código llama a la función plot_preds, que se utiliza para visualizar las predicciones del modelo y compararlas con los valores reales (y) y las predicciones de la función f (la \"verdad base\" o el modelo original)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GNomS3RhRZ28",
        "outputId": "80e18a43-5a51-4984-a5c6-9be4fa0e2e8c"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# 5. Resultados\n",
        "# ============================\n",
        "print(\"\\nPesos aprendidos:\")\n",
        "print(\"W =\", modelo.W.numpy().flatten())\n",
        "print(\"b =\", modelo.b.numpy())\n",
        "\n",
        "# Graficamos la evolución de la pérdida\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Época\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Entrenamiento de una sola neurona\")\n",
        "plt.show()\n",
        "\n",
        "# Graficamos la predicción vs datos\n",
        "plt.scatter(x, y, label=\"Datos con ruido\", s=10)\n",
        "plt.plot(x, f(x), label=\"Función real\", linewidth=2)\n",
        "plt.plot(x, modelo(X), label=\"Modelo entrenado\", linewidth=2, linestyle=\"--\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s4D4czWAUVmo",
        "outputId": "77d34256-0e9c-463f-ed09-c8b4dfa5b99a"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# 5. Resultados\n",
        "# ============================\n",
        "print(\"\\nPesos aprendidos:\")\n",
        "print(\"W =\", modelo.W.numpy().flatten())\n",
        "print(\"b =\", modelo.b.numpy())\n",
        "\n",
        "# Graficamos la evolución de la pérdida\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"Época\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.title(\"Entrenamiento de una sola neurona\")\n",
        "plt.show()\n",
        "\n",
        "# Graficamos la predicción vs datos\n",
        "plt.scatter(x, y, label=\"Datos con ruido\", s=10)\n",
        "plt.plot(x, f(x), label=\"Función real\", linewidth=2)\n",
        "plt.plot(x, modelo(X), label=\"Modelo entrenado\", linewidth=2, linestyle=\"--\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4faNe-nSUuGM"
      },
      "source": [
        "#Keras\n",
        "\n",
        "El modelo quedó entrenado y tiene buenos resultados, pero podemos hacer las implementaciones de utilidades de manera más fácil y sencilla usnado utilidades comunes de entrenamiento están disponibles en el módulo tf.keras.\n",
        "\n",
        "Por lo tanto vamos a considera utilizar esas funciones en la siguiente sección antes de escribir las propias, como hicimos anteriormente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fhphi73Vkjc"
      },
      "source": [
        "**Keras** es una interfaz de alto nivel para TensorFlow, diseñada para facilitar y agilizar la implementación de soluciones de aprendizaje automático (ML), con un enfoque principal en el aprendizaje profundo.\n",
        "\n",
        "Esta biblioteca cubre todo el flujo de trabajo de ML, desde la preparación de datos hasta la implementación del modelo, pasando por el ajuste de hiperparámetros. Su principal objetivo es permitir una experimentación rápida y eficiente.\n",
        "\n",
        "\n",
        "Con Keras, se obtiene acceso completo a la escalabilidad y las capacidades multidispositivo de TensorFlow. Es posible ejecutar modelos en dispositivos potentes como TPUs o clusters de GPU, y también exportar modelos entrenados para su uso en navegadores web o dispositivos móviles. Además, Keras ofrece la posibilidad de desplegar modelos como APIs web.\n",
        "\n",
        "\n",
        "El diseño de Keras está orientado a reducir la carga cognitiva, enfocándose en los siguientes aspectos:\n",
        "\n",
        "\n",
        "1. Proporcionar interfaces simples y consistentes.\n",
        "2. Minimizar la cantidad de pasos necesarios para realizar tareas comunes.\n",
        "3. Ofrecer mensajes de error claros y fáciles de entender.\n",
        "4. Seguir el principio de \"divulgación progresiva de complejidad\", donde el usuario puede comenzar fácilmente y aprender gradualmente a medida que avanza en tareas más complejas.\n",
        "5. Fomentar la escritura de código conciso y legible.\n",
        "\n",
        "\n",
        "**Utilizar Keras**\n",
        "\n",
        "Cualquier persona que utilice TensorFlow debería hacerlo a través de la API de Keras. Ya sea un ingeniero, un investigador o un profesional del aprendizaje automático, Keras es la opción recomendada para comenzar.\n",
        "\n",
        "\n",
        "Existen casos específicos, como la creación de herramientas sobre TensorFlow o el desarrollo de plataformas de alto rendimiento personalizadas, donde puede ser necesario utilizar las APIs de bajo nivel de TensorFlow. Sin embargo, para la mayoría de los usuarios, Keras será la opción preferida.\n",
        "\n",
        "\n",
        "**Componentes principales de Keras**\n",
        "\n",
        "Keras está basado en dos estructuras de datos clave:\n",
        "*capas y modelos*. Una **capa** es una función que realiza una transformación entre las entradas y las salidas, mientras que un **modelo** es un gráfico acíclico dirigido (DAG) de capas.\n",
        "\n",
        "##Capas\n",
        "\n",
        "La clase *tf.keras.layers.Layer* es la piedra angular de Keras. Cada capa encapsula un conjunto de pesos y realiza ciertos cálculos a través del método call. Los pesos que se crean pueden ser entrenables o no, y las capas pueden estar compuestas de manera recursiva. Es decir, una capa puede contener otras capas como atributos, permitiendo que la capa externa gestione los pesos de las capas internas.\n",
        "\n",
        "Además, las capas pueden utilizarse para tareas de preprocesamiento, como normalización de datos o vectorización de texto. Estas capas de preprocesamiento pueden integrarse directamente en el modelo, permitiendo su portabilidad tanto durante como después del entrenamiento.\n",
        "\n",
        "##Modelos\n",
        "\n",
        "Un modelo es un objeto que agrupa capas y que puede ser entrenado con datos. El tipo de modelo más sencillo es el modelo secuencial, que organiza las capas en una pila lineal. Para arquitecturas más complejas, Keras permite utilizar la API funcional, que facilita la creación de gráficos arbitrarios de capas, o incluso escribir modelos completamente personalizados utilizando subclases.\n",
        "\n",
        "\n",
        "La clase *tf.keras.Model* proporciona métodos integrados para entrenar y evaluar modelos:\n",
        "\n",
        "***fit***: Entrena el modelo durante un número determinado de épocas.\n",
        "\n",
        "***predict***: Genera predicciones a partir de las entradas.\n",
        "\n",
        "***evaluate***: Devuelve la pérdida y las métricas del modelo, configuradas a través del método compile.\n",
        "\n",
        "Estos métodos ofrecen acceso a varias funcionalidades útiles durante el entrenamiento:\n",
        "\n",
        "***Callbacks:*** Permiten detener el entrenamiento anticipadamente, establecer puntos de control del modelo y monitorear el proceso mediante TensorBoard. También es posible implementar callbacks personalizados.\n",
        "\n",
        "\n",
        "***Entrenamiento distribuido:*** Keras facilita la extensión del entrenamiento a múltiples GPUs, TPUs o dispositivos.\n",
        "\n",
        "***Fusión escalonada:*** Al configurar steps_per_execution en compile, se pueden procesar varios lotes en una sola llamada de tf.function, mejorando la utilización del dispositivo, especialmente en TPUs.\n",
        "\n",
        "Para más detalles sobre cómo utilizar el método fit, consulta la guía de entrenamiento y evaluación. Si deseas personalizar el ciclo de entrenamiento y evaluación, puedes consultar la sección sobre personalización de fi().\n",
        "\n",
        "###Otras herramientas y APIs de Keras\n",
        "\n",
        "Keras ofrece una variedad de APIs y herramientas adicionales para el aprendizaje profundo, entre las que se incluyen:\n",
        "\n",
        "* Optimizadores\n",
        "* Métricas\n",
        "* Funciones de pérdida\n",
        "* Utilidades para la carga de datos\n",
        "\n",
        "Estas herramientas complementan la experiencia de entrenamiento y son fundamentales para optimizar y evaluar modelos de aprendizaje profundo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDlpUPXnXA9p"
      },
      "source": [
        "Vamos a realizar el ejercicio que hicimos en Tensorflow donde modelamos nuestras propias funciones para usar Keras.\n",
        "\n",
        "\n",
        "Empecemos creando un Modelo Secuencial en Keras utilizando tf.keras.Sequential. Una de las capas más simples de Keras es la capa densa (Dense), que se puede instanciar con tf.keras.layers.Dense. La capa densa es capaz de aprender relaciones lineales multidimensionales de la forma  $𝑌=𝑊𝑋+𝑏$. Para aprender una ecuación no lineal de la forma $𝑤_1𝑥^2+𝑤_2𝑥+𝑏$​, la entrada de la capa densa debe ser una matriz de datos con $𝑥^2$  y $x$ como características.\n",
        "\n",
        "La capa lambda *tf.keras.layers.Lambda* se puede usar para realizar esta transformación de apilamiento.\n",
        "\n",
        "\n",
        "1. La primera capa es una capa Lambda. Esta capa aplica una transformación personalizada sobre los datos.\n",
        "En este caso, estamos apilando dos características: $'x'$ y $'x^2$' a lo largo del eje 1 (columnas) utilizando tf.stack.\n",
        "Esto permite que el modelo reciba como entrada tanto $x$ como $x^2$, lo cual es útil para aprender relaciones no lineales.\n",
        "\n",
        "2. La siguiente capa es una capa densa (Dense). Esta capa realizará una combinación lineal de las entradas que recibe.\n",
        "'units=1' significa que la capa tendrá una sola unidad de salida (un solo valor de predicción).\n",
        "'kernel_initializer=tf.random.normal' inicializa los pesos de la capa de forma aleatoria usando una distribución normal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwkFnLmIs9y3",
        "outputId": "23e48750-717a-4b95-9654-9f8e9998e6ef"
      },
      "outputs": [],
      "source": [
        "data = np.column_stack((x.numpy(), (x.numpy()**2),y.numpy()))\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH5YlvmOIoJo"
      },
      "source": [
        "## Declaración de la red\n",
        "\n",
        "### Lambda layer:\n",
        "\n",
        "Toma la entrada x y la transforma en un vector [x, x²].\n",
        "\n",
        "Es decir, pasa de tener 1 característica → 2 características.\n",
        "\n",
        "Dense(units=1):\n",
        "\n",
        "Esto es una capa densa con 1 neurona.\n",
        "\n",
        "Esa neurona recibe las 2 entradas (x y x²) y calcula:\n",
        "\n",
        "$𝑦=𝑤1⋅𝑥+𝑤2⋅𝑥2+𝑏$\n",
        "\n",
        "Es un modelo lineal en 2 variables (pero no hay función de activación, así que la salida es lineal)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "praHocfIYIKi"
      },
      "outputs": [],
      "source": [
        "modelo_keras = tf.keras.Sequential([\n",
        "    tf.keras.layers.Lambda(lambda x: tf.stack([x, x**2], axis=1)),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1,\n",
        "        kernel_initializer=tf.keras.initializers.RandomNormal(seed=42),  # kernel reproducible\n",
        "    )\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "Y8LYAGRUtEvV",
        "outputId": "0ed68948-00e6-45f2-e9c6-575ec0a65aaf"
      },
      "outputs": [],
      "source": [
        "modelo_keras.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "vvDKynLfYTi0"
      },
      "outputs": [],
      "source": [
        "# Compilamos el modelo con una función de pérdida MSE (error cuadrático medio) y un optimizador SGD con tasa de aprendizaje de 0.01.\n",
        "modelo_keras.compile(\n",
        "    loss=tf.keras.losses.MSE,\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MICragmtMgo",
        "outputId": "b4ce31c7-e493-48aa-c178-0f310504d3d9"
      },
      "outputs": [],
      "source": [
        "# Entrenamos el modelo durante 100 épocas con un tamaño de lote de 32, utilizando los datos de entrada x y las etiquetas y.\n",
        "history = modelo_keras.fit(x, y, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "qLADH6dqtRVX"
      },
      "outputs": [],
      "source": [
        "# Guardamos el modelo entrenado en un archivo para su uso posterior.\n",
        "modelo_keras.save('./modelo_keras.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "DT1j_yg-aB7a",
        "outputId": "a7c9b01c-548a-4b58-e413-f5330034514d"
      },
      "outputs": [],
      "source": [
        "modelo_keras.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X821_TGaF8B"
      },
      "source": [
        "Vamos a predecir un conjunto de valores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZqvEy9baJLo",
        "outputId": "e859ae6c-a789-4755-8128-a3cb62b5b895"
      },
      "outputs": [],
      "source": [
        "# Realizamos predicciones utilizando el modelo entrenado con los datos de entrada x.\n",
        "predicciones = modelo_keras.predict(x)\n",
        "\n",
        "# Las predicciones son una lista de valores de salida generados por el modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vYWXiDMajj3",
        "outputId": "a0a1822a-7c32-46bb-aa38-d78370e045fd"
      },
      "outputs": [],
      "source": [
        "predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "qo6iq2ivamTv",
        "outputId": "aa240033-b91a-4db3-e6f0-78e98217c6dc"
      },
      "outputs": [],
      "source": [
        "  # Graficar los datos reales (con ruido) usando puntos\n",
        "  plt.plot(x, y, '.', label='Data')  # 'x' es la entrada y 'y' son los datos generados con ruido\n",
        "\n",
        "  # Graficar la \"verdad fundamental\" (la función sin ruido) con una línea\n",
        "  plt.plot(x, f(x), label='Ground truth')  # 'f(x)' es la función cuadrática original sin ruido\n",
        "\n",
        "  # Graficar las predicciones del modelo usando una línea\n",
        "  plt.plot(x, predicciones, label='Predictions')  #son las predicciones del modelo entrenado\n",
        "\n",
        "  # Añadir un título al gráfico\n",
        "  plt.title(\"Modelo entrenado con Keras\")  # El título se pasa como argumento a la función\n",
        "\n",
        "  # Mostrar la leyenda para identificar las diferentes líneas\n",
        "  plt.legend()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
